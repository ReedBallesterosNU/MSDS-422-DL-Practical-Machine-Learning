{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77936794",
   "metadata": {},
   "source": [
    "# Module 7 Assignment 3: Digit Recognizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f22b91e",
   "metadata": {},
   "source": [
    "**Reed Ballesteros**\n",
    "\n",
    "**MSDS-422**\n",
    "\n",
    "**5/15/2022**\n",
    "\n",
    "**Instructor: Prof. Noah Gift**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a6de3b",
   "metadata": {},
   "source": [
    "# Digit Recognizer (https://www.kaggle.com/c/digit-recognizer) \n",
    "\n",
    "### Background Materials\n",
    "This week, you will compete in the classic MNIST Digit Recognizer (Links to an external site.) competition using neural networks.\n",
    "\n",
    "### Management/Research Question\n",
    "In laymanâ€™s terms, what is the management/research question of interest, and why would anyone care?  \n",
    "\n",
    "### Requirements\n",
    "- Conduct your analysis using a cross-validation design.\n",
    "- Conduct / refine EDA.\n",
    "- Conduct Design of Experiments to evaluate the performance of various neural networks by changing the layers and nodes. Tested neural network structures should be explored within a benchmark experiment, a 2x2 completely crossed design. An example of a completely crossed designed with {2, 5} layers and {10,20} nodes follows.\n",
    "\n",
    "Layers| Nodes| Time| Training Accuracy| Testing Accuracy\n",
    "---|---|---|---|---\n",
    "2| 10| 63.61| 0.935| 0.927\n",
    "2| 20| 115.25| 0.967| 0.952\n",
    "5| 10| 74.28| 0.944| 0.933\n",
    "5| 20| 75.1| 0.964| 0.952\n",
    "\n",
    "-  Due to the time required to fit each neural network, we will observe only one trial for each cell in the design. \n",
    "- You will build your models on csv and submit your forecasts for test.csv to Kaggle.com, providing your name and user ID for each experimental trial. \n",
    "- Evaluate goodness of fit metrics on the training and validation sets.\n",
    "- Provide a multi-class confusion matrix.\n",
    "- Discuss how your models performed.\n",
    "\n",
    "In summary, this assignment asks you to fit a number of neural networks, comparing processing time and performance across experimental treatments. Processing time will be recorded for the fitting on the train.csv. Kaggle.com accuracy scores will be reported for all benchmarks.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad5aa62",
   "metadata": {},
   "source": [
    "### Libraries to be loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fa7647a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "from matplotlib import pyplot\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08214e05",
   "metadata": {},
   "source": [
    "## Ingest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2dd11184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 785)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a34f755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28000, 784)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"test.csv\")\n",
    "test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e63e5c",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c816eb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_X = train_df.copy()\n",
    "train_df_y = train_df_X['label']\n",
    "train_df_X.drop(['label'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e172f13a",
   "metadata": {},
   "source": [
    "## MODELLING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01912e0e",
   "metadata": {},
   "source": [
    "Let's split train.csv 80/20 into training and validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5494c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_val,y_train,y_val=train_test_split(train_df_X,train_df_y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730932d0",
   "metadata": {},
   "source": [
    "### NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "8fbc4165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.\\\\my_mnist_logs\\\\run_001'"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.rmtree('my_mnist_logs')\n",
    "run_index = 1 # increment this at every run\n",
    "run_logdir = os.path.join(os.curdir, \"my_mnist_logs\", \"run_{:03d}\".format(run_index))\n",
    "run_logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "96d1d979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 167,818\n",
      "Trainable params: 167,818\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "new_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "new_model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=tf.keras.optimizers.Adam(lr=0.001),\n",
    "              metrics=[\"sparse_categorical_accuracy\"]\n",
    "            )\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "adaa7b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input Tensor(\"flatten_input:0\", shape=(None, 28, 28), dtype=float32), but it was called on an input with incompatible shape (32, 784).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input Tensor(\"flatten_input:0\", shape=(None, 28, 28), dtype=float32), but it was called on an input with incompatible shape (32, 784).\n",
      "   2/1050 [..............................] - ETA: 48s - loss: 21.4718 - sparse_categorical_accuracy: 0.1094WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0020s vs `on_train_batch_end` time: 0.0910s). Check your callbacks.\n",
      "1016/1050 [============================>.] - ETA: 0s - loss: 0.6348 - sparse_categorical_accuracy: 0.8561WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input Tensor(\"flatten_input:0\", shape=(None, 28, 28), dtype=float32), but it was called on an input with incompatible shape (None, 784).\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.30006, saving model to yo_model.h5\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.6220 - sparse_categorical_accuracy: 0.8585 - val_loss: 0.3001 - val_sparse_categorical_accuracy: 0.9136\n",
      "Epoch 2/100\n",
      "1021/1050 [============================>.] - ETA: 0s - loss: 0.2268 - sparse_categorical_accuracy: 0.9343\n",
      "Epoch 00002: val_loss improved from 0.30006 to 0.21893, saving model to yo_model.h5\n",
      "1050/1050 [==============================] - 2s 1ms/step - loss: 0.2269 - sparse_categorical_accuracy: 0.9343 - val_loss: 0.2189 - val_sparse_categorical_accuracy: 0.9360\n",
      "Epoch 3/100\n",
      "1050/1050 [==============================] - ETA: 0s - loss: 0.1758 - sparse_categorical_accuracy: 0.9495\n",
      "Epoch 00003: val_loss improved from 0.21893 to 0.18711, saving model to yo_model.h5\n",
      "1050/1050 [==============================] - 2s 1ms/step - loss: 0.1758 - sparse_categorical_accuracy: 0.9495 - val_loss: 0.1871 - val_sparse_categorical_accuracy: 0.9423\n",
      "Epoch 4/100\n",
      "1043/1050 [============================>.] - ETA: 0s - loss: 0.1499 - sparse_categorical_accuracy: 0.9568\n",
      "Epoch 00004: val_loss improved from 0.18711 to 0.17911, saving model to yo_model.h5\n",
      "1050/1050 [==============================] - 2s 1ms/step - loss: 0.1497 - sparse_categorical_accuracy: 0.9569 - val_loss: 0.1791 - val_sparse_categorical_accuracy: 0.9530\n",
      "Epoch 5/100\n",
      "1031/1050 [============================>.] - ETA: 0s - loss: 0.1282 - sparse_categorical_accuracy: 0.9632\n",
      "Epoch 00005: val_loss improved from 0.17911 to 0.15988, saving model to yo_model.h5\n",
      "1050/1050 [==============================] - 2s 1ms/step - loss: 0.1279 - sparse_categorical_accuracy: 0.9632 - val_loss: 0.1599 - val_sparse_categorical_accuracy: 0.9567\n",
      "Epoch 6/100\n",
      "1026/1050 [============================>.] - ETA: 0s - loss: 0.1087 - sparse_categorical_accuracy: 0.9689\n",
      "Epoch 00006: val_loss did not improve from 0.15988\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.1098 - sparse_categorical_accuracy: 0.9687 - val_loss: 0.1635 - val_sparse_categorical_accuracy: 0.9573\n",
      "Epoch 7/100\n",
      "1024/1050 [============================>.] - ETA: 0s - loss: 0.1024 - sparse_categorical_accuracy: 0.9716\n",
      "Epoch 00007: val_loss improved from 0.15988 to 0.14310, saving model to yo_model.h5\n",
      "1050/1050 [==============================] - 2s 1ms/step - loss: 0.1026 - sparse_categorical_accuracy: 0.9715 - val_loss: 0.1431 - val_sparse_categorical_accuracy: 0.9613\n",
      "Epoch 8/100\n",
      "1013/1050 [===========================>..] - ETA: 0s - loss: 0.0913 - sparse_categorical_accuracy: 0.9740\n",
      "Epoch 00008: val_loss did not improve from 0.14310\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.0906 - sparse_categorical_accuracy: 0.9743 - val_loss: 0.1683 - val_sparse_categorical_accuracy: 0.9611\n",
      "Epoch 9/100\n",
      "1036/1050 [============================>.] - ETA: 0s - loss: 0.0854 - sparse_categorical_accuracy: 0.9765\n",
      "Epoch 00009: val_loss did not improve from 0.14310\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.0853 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.1996 - val_sparse_categorical_accuracy: 0.9552\n",
      "Epoch 10/100\n",
      "1019/1050 [============================>.] - ETA: 0s - loss: 0.0816 - sparse_categorical_accuracy: 0.9781\n",
      "Epoch 00010: val_loss improved from 0.14310 to 0.13382, saving model to yo_model.h5\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.0815 - sparse_categorical_accuracy: 0.9780 - val_loss: 0.1338 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 11/100\n",
      "1035/1050 [============================>.] - ETA: 0s - loss: 0.0708 - sparse_categorical_accuracy: 0.9806\n",
      "Epoch 00011: val_loss did not improve from 0.13382\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.0707 - sparse_categorical_accuracy: 0.9806 - val_loss: 0.1490 - val_sparse_categorical_accuracy: 0.9633\n",
      "Epoch 12/100\n",
      "1043/1050 [============================>.] - ETA: 0s - loss: 0.0631 - sparse_categorical_accuracy: 0.9827\n",
      "Epoch 00012: val_loss did not improve from 0.13382\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.0637 - sparse_categorical_accuracy: 0.9826 - val_loss: 0.1682 - val_sparse_categorical_accuracy: 0.9654\n",
      "Epoch 13/100\n",
      "1038/1050 [============================>.] - ETA: 0s - loss: 0.0602 - sparse_categorical_accuracy: 0.9839\n",
      "Epoch 00013: val_loss did not improve from 0.13382\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.0601 - sparse_categorical_accuracy: 0.9840 - val_loss: 0.2125 - val_sparse_categorical_accuracy: 0.9645\n",
      "Epoch 14/100\n",
      "1031/1050 [============================>.] - ETA: 0s - loss: 0.0722 - sparse_categorical_accuracy: 0.9810\n",
      "Epoch 00014: val_loss did not improve from 0.13382\n",
      "1050/1050 [==============================] - 2s 1ms/step - loss: 0.0716 - sparse_categorical_accuracy: 0.9811 - val_loss: 0.1698 - val_sparse_categorical_accuracy: 0.9629\n",
      "Epoch 15/100\n",
      "1040/1050 [============================>.] - ETA: 0s - loss: 0.0532 - sparse_categorical_accuracy: 0.9852\n",
      "Epoch 00015: val_loss did not improve from 0.13382\n",
      "1050/1050 [==============================] - 2s 1ms/step - loss: 0.0542 - sparse_categorical_accuracy: 0.9851 - val_loss: 0.1542 - val_sparse_categorical_accuracy: 0.9688\n",
      "Epoch 16/100\n",
      "1015/1050 [============================>.] - ETA: 0s - loss: 0.0597 - sparse_categorical_accuracy: 0.9840\n",
      "Epoch 00016: val_loss did not improve from 0.13382\n",
      "1050/1050 [==============================] - 2s 1ms/step - loss: 0.0595 - sparse_categorical_accuracy: 0.9840 - val_loss: 0.1733 - val_sparse_categorical_accuracy: 0.9657\n",
      "Epoch 17/100\n",
      "1047/1050 [============================>.] - ETA: 0s - loss: 0.0486 - sparse_categorical_accuracy: 0.9861\n",
      "Epoch 00017: val_loss did not improve from 0.13382\n",
      "1050/1050 [==============================] - 2s 1ms/step - loss: 0.0486 - sparse_categorical_accuracy: 0.9861 - val_loss: 0.1631 - val_sparse_categorical_accuracy: 0.9700\n",
      "Epoch 18/100\n",
      "1036/1050 [============================>.] - ETA: 0s - loss: 0.0478 - sparse_categorical_accuracy: 0.9876\n",
      "Epoch 00018: val_loss did not improve from 0.13382\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.0475 - sparse_categorical_accuracy: 0.9877 - val_loss: 0.1869 - val_sparse_categorical_accuracy: 0.9706\n",
      "Epoch 19/100\n",
      "1036/1050 [============================>.] - ETA: 0s - loss: 0.0440 - sparse_categorical_accuracy: 0.9888\n",
      "Epoch 00019: val_loss did not improve from 0.13382\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.0436 - sparse_categorical_accuracy: 0.9889 - val_loss: 0.1525 - val_sparse_categorical_accuracy: 0.9712\n",
      "Epoch 20/100\n",
      "1010/1050 [===========================>..] - ETA: 0s - loss: 0.0482 - sparse_categorical_accuracy: 0.9888\n",
      "Epoch 00020: val_loss did not improve from 0.13382\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.0494 - sparse_categorical_accuracy: 0.9885 - val_loss: 0.2013 - val_sparse_categorical_accuracy: 0.9612\n",
      "Epoch 21/100\n",
      "1044/1050 [============================>.] - ETA: 0s - loss: 0.0426 - sparse_categorical_accuracy: 0.9892\n",
      "Epoch 00021: val_loss did not improve from 0.13382\n",
      "1050/1050 [==============================] - 2s 1ms/step - loss: 0.0428 - sparse_categorical_accuracy: 0.9892 - val_loss: 0.2418 - val_sparse_categorical_accuracy: 0.9665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100\n",
      "1020/1050 [============================>.] - ETA: 0s - loss: 0.0549 - sparse_categorical_accuracy: 0.9870\n",
      "Epoch 00022: val_loss did not improve from 0.13382\n",
      "1050/1050 [==============================] - 2s 1ms/step - loss: 0.0547 - sparse_categorical_accuracy: 0.9870 - val_loss: 0.1830 - val_sparse_categorical_accuracy: 0.9694\n",
      "Epoch 23/100\n",
      "1028/1050 [============================>.] - ETA: 0s - loss: 0.0319 - sparse_categorical_accuracy: 0.9912\n",
      "Epoch 00023: val_loss did not improve from 0.13382\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.0326 - sparse_categorical_accuracy: 0.9910 - val_loss: 0.2257 - val_sparse_categorical_accuracy: 0.9613\n",
      "Epoch 24/100\n",
      "1011/1050 [===========================>..] - ETA: 0s - loss: 0.0500 - sparse_categorical_accuracy: 0.9896\n",
      "Epoch 00024: val_loss did not improve from 0.13382\n",
      "1050/1050 [==============================] - 2s 1ms/step - loss: 0.0490 - sparse_categorical_accuracy: 0.9897 - val_loss: 0.1943 - val_sparse_categorical_accuracy: 0.9695\n",
      "Epoch 25/100\n",
      "1016/1050 [============================>.] - ETA: 0s - loss: 0.0356 - sparse_categorical_accuracy: 0.9914\n",
      "Epoch 00025: val_loss did not improve from 0.13382\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.0360 - sparse_categorical_accuracy: 0.9914 - val_loss: 0.1924 - val_sparse_categorical_accuracy: 0.9717\n",
      "Epoch 26/100\n",
      "1026/1050 [============================>.] - ETA: 0s - loss: 0.0331 - sparse_categorical_accuracy: 0.9919\n",
      "Epoch 00026: val_loss did not improve from 0.13382\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.0331 - sparse_categorical_accuracy: 0.9919 - val_loss: 0.2048 - val_sparse_categorical_accuracy: 0.9735\n",
      "Epoch 27/100\n",
      "1025/1050 [============================>.] - ETA: 0s - loss: 0.0447 - sparse_categorical_accuracy: 0.9911\n",
      "Epoch 00027: val_loss did not improve from 0.13382\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.0446 - sparse_categorical_accuracy: 0.9910 - val_loss: 0.1970 - val_sparse_categorical_accuracy: 0.9690\n",
      "Epoch 28/100\n",
      "1033/1050 [============================>.] - ETA: 0s - loss: 0.0251 - sparse_categorical_accuracy: 0.9940\n",
      "Epoch 00028: val_loss did not improve from 0.13382\n",
      "1050/1050 [==============================] - 2s 1ms/step - loss: 0.0252 - sparse_categorical_accuracy: 0.9940 - val_loss: 0.1644 - val_sparse_categorical_accuracy: 0.9711\n",
      "Epoch 29/100\n",
      "1042/1050 [============================>.] - ETA: 0s - loss: 0.0333 - sparse_categorical_accuracy: 0.992 - ETA: 0s - loss: 0.0328 - sparse_categorical_accuracy: 0.9924\n",
      "Epoch 00029: val_loss did not improve from 0.13382\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.0327 - sparse_categorical_accuracy: 0.9924 - val_loss: 0.2152 - val_sparse_categorical_accuracy: 0.9696\n",
      "Epoch 30/100\n",
      "1022/1050 [============================>.] - ETA: 0s - loss: 0.0331 - sparse_categorical_accuracy: 0.9925\n",
      "Epoch 00030: val_loss did not improve from 0.13382\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.0324 - sparse_categorical_accuracy: 0.9927 - val_loss: 0.3221 - val_sparse_categorical_accuracy: 0.9712\n",
      "Epoch 00030: early stopping\n"
     ]
    }
   ],
   "source": [
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "                    verbose=1,patience=20)\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"yo_model.h5\",verbose=1,save_best_only=True)\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir)\n",
    "\n",
    "history = new_model.fit(X_train, y_train, epochs=100,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    callbacks=[checkpoint_cb, early_stopping_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "f62c16ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "a2df1d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input Tensor(\"flatten_input_1:0\", shape=(None, 28, 28), dtype=float32), but it was called on an input with incompatible shape (None, 784).\n",
      "263/263 [==============================] - 0s 650us/step - loss: 0.1338 - sparse_categorical_accuracy: 0.9663\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1338234692811966, 0.9663095474243164]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = tf.keras.models.load_model(\"yo_model.h5\") # rollback to best model\n",
    "best_model.evaluate(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "2308a642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input Tensor(\"flatten_input_1:0\", shape=(None, 28, 28), dtype=float32), but it was called on an input with incompatible shape (32, 784).\n",
      "1050/1050 [==============================] - 1s 912us/step - loss: 0.0457 - sparse_categorical_accuracy: 0.9873\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.045716192573308945, 0.9873214364051819]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.evaluate(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "ba6de8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext tensorboard\n",
    "%reload_ext tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "0baec67a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 9584), started 0:04:53 ago. (Use '!kill 9584' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-e1529f5ff72e6f52\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-e1529f5ff72e6f52\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=./my_mnist_logs --port=6006\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "d3be73d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input Tensor(\"flatten_input_1:0\", shape=(None, 28, 28), dtype=float32), but it was called on an input with incompatible shape (32, 784).\n"
     ]
    }
   ],
   "source": [
    "y_test = best_model.predict(test_df)\n",
    "y = []\n",
    "for i in range (0, len(y_test)):\n",
    "    y.append(np.argmax(y_test[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "c343889f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create submission file\n",
    "submission = pd.DataFrame({\"ImageId\": (test_df.index + 1),\"Label\": y})\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bff0be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
